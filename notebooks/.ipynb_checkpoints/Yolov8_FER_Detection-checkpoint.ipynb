{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75bba99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "#from skimage.transform import resize as sk_resize\n",
    "\n",
    "# object classes\n",
    "#classNames = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprise','neutral'] #FER2013\n",
    "#classNames = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'] #AffectnetYoloAnnotated\n",
    "face_detect = dlib.get_frontal_face_detector()\n",
    "model = YOLO(\"../Model/yolofer2013best/best.pt\") #FER2013 Model\n",
    "#model = YOLO(\"../Model/yolofer2013best/gdrive.torchscript\") #FER2013 Model\n",
    "#model = YOLO(\"../Model/yolofer2013best/best_prev.pt\") #FER2013 Model\n",
    "#model = YOLO(\"../Model/AFFECTNETYOLObest/best.pt\") #AffectnetModel\n",
    "#result=model.predict(source=\"0\",show=True)\n",
    "predictor_landmarks  = dlib.shape_predictor(\"../Model/face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2569b3-4f0c-462a-8ab3-d55b17b40d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success ✅ (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 320x416 1 happy, 164.5ms\n",
      "0: 320x416 1 happy, 159.0ms\n",
      "0: 320x416 1 happy, 186.5ms\n",
      "0: 320x416 1 happy, 160.6ms\n",
      "0: 320x416 1 happy, 175.9ms\n",
      "0: 320x416 1 happy, 169.4ms\n",
      "0: 320x416 1 happy, 189.2ms\n",
      "0: 320x416 1 happy, 155.8ms\n",
      "0: 320x416 1 happy, 196.7ms\n",
      "0: 320x416 1 happy, 232.6ms\n",
      "0: 320x416 (no detections), 186.2ms\n",
      "0: 320x416 (no detections), 130.1ms\n",
      "0: 320x416 (no detections), 141.7ms\n",
      "0: 320x416 (no detections), 144.5ms\n",
      "0: 320x416 (no detections), 140.0ms\n",
      "0: 320x416 1 happy, 157.8ms\n",
      "0: 320x416 (no detections), 152.1ms\n",
      "0: 320x416 (no detections), 140.8ms\n",
      "0: 320x416 (no detections), 126.0ms\n",
      "0: 320x416 (no detections), 143.4ms\n",
      "0: 320x416 (no detections), 127.9ms\n",
      "0: 320x416 (no detections), 128.3ms\n",
      "0: 320x416 (no detections), 113.5ms\n",
      "0: 320x416 (no detections), 123.9ms\n",
      "0: 320x416 (no detections), 122.8ms\n",
      "0: 320x416 (no detections), 136.0ms\n",
      "0: 320x416 (no detections), 112.8ms\n",
      "0: 320x416 1 happy, 132.2ms\n",
      "0: 320x416 (no detections), 127.3ms\n",
      "0: 320x416 (no detections), 119.4ms\n",
      "0: 320x416 (no detections), 108.6ms\n",
      "0: 320x416 (no detections), 128.3ms\n",
      "0: 320x416 (no detections), 129.5ms\n",
      "0: 320x416 1 anger, 143.6ms\n",
      "0: 320x416 1 anger, 146.0ms\n",
      "0: 320x416 1 anger, 132.9ms\n",
      "0: 320x416 1 anger, 181.6ms\n",
      "0: 320x416 1 anger, 158.2ms\n",
      "0: 320x416 (no detections), 146.0ms\n",
      "0: 320x416 (no detections), 112.8ms\n",
      "0: 320x416 (no detections), 212.3ms\n",
      "0: 320x416 1 anger, 180.5ms\n",
      "0: 320x416 (no detections), 188.7ms\n",
      "0: 320x416 1 anger, 129.1ms\n",
      "0: 320x416 1 anger, 115.5ms\n",
      "0: 320x416 1 anger, 128.8ms\n",
      "0: 320x416 1 anger, 147.2ms\n",
      "0: 320x416 (no detections), 112.4ms\n",
      "0: 320x416 1 anger, 119.9ms\n",
      "0: 320x416 1 anger, 119.2ms\n",
      "0: 320x416 1 anger, 128.8ms\n",
      "0: 320x416 1 anger, 121.4ms\n",
      "0: 320x416 1 anger, 113.6ms\n",
      "0: 320x416 1 anger, 131.4ms\n",
      "0: 320x416 1 anger, 112.4ms\n",
      "0: 320x416 1 anger, 128.0ms\n",
      "0: 320x416 1 anger, 110.5ms\n",
      "0: 320x416 1 anger, 127.6ms\n",
      "0: 320x416 (no detections), 144.3ms\n",
      "0: 320x416 (no detections), 112.5ms\n",
      "0: 320x416 1 anger, 124.9ms\n",
      "0: 320x416 1 anger, 126.4ms\n",
      "0: 320x416 1 anger, 128.0ms\n",
      "0: 320x416 1 anger, 107.5ms\n",
      "0: 320x416 1 anger, 126.9ms\n",
      "0: 320x416 1 anger, 128.0ms\n",
      "0: 320x416 1 anger, 123.8ms\n",
      "0: 320x416 1 anger, 126.6ms\n",
      "0: 320x416 1 anger, 128.8ms\n",
      "0: 320x416 1 anger, 128.5ms\n",
      "0: 320x416 1 anger, 128.0ms\n",
      "0: 320x416 1 anger, 128.2ms\n",
      "0: 320x416 1 anger, 128.2ms\n",
      "0: 320x416 1 anger, 158.3ms\n",
      "0: 320x416 1 anger, 120.1ms\n",
      "0: 320x416 1 anger, 123.4ms\n",
      "0: 320x416 1 anger, 112.0ms\n",
      "0: 320x416 1 anger, 110.5ms\n",
      "0: 320x416 1 anger, 180.2ms\n",
      "0: 320x416 1 anger, 190.7ms\n",
      "0: 320x416 1 anger, 145.4ms\n",
      "0: 320x416 1 anger, 144.1ms\n",
      "0: 320x416 1 anger, 128.1ms\n",
      "0: 320x416 1 anger, 143.7ms\n",
      "0: 320x416 1 anger, 129.1ms\n",
      "0: 320x416 1 anger, 142.7ms\n",
      "0: 320x416 1 anger, 128.0ms\n",
      "0: 320x416 1 anger, 123.4ms\n",
      "0: 320x416 1 anger, 128.2ms\n",
      "0: 320x416 1 anger, 127.5ms\n",
      "0: 320x416 1 anger, 124.4ms\n",
      "0: 320x416 1 anger, 119.7ms\n",
      "0: 320x416 1 anger, 127.8ms\n",
      "0: 320x416 1 anger, 128.4ms\n",
      "0: 320x416 1 anger, 129.0ms\n",
      "0: 320x416 1 anger, 111.2ms\n",
      "0: 320x416 1 anger, 123.4ms\n",
      "0: 320x416 1 anger, 112.1ms\n",
      "0: 320x416 1 anger, 113.4ms\n",
      "0: 320x416 1 anger, 121.9ms\n",
      "0: 320x416 1 anger, 111.5ms\n",
      "0: 320x416 1 anger, 240.2ms\n",
      "0: 320x416 1 anger, 128.2ms\n",
      "0: 320x416 1 anger, 128.0ms\n",
      "0: 320x416 1 anger, 111.9ms\n",
      "0: 320x416 1 anger, 112.7ms\n",
      "0: 320x416 1 anger, 128.3ms\n",
      "0: 320x416 1 anger, 127.4ms\n",
      "0: 320x416 1 anger, 138.7ms\n",
      "0: 320x416 1 anger, 139.7ms\n",
      "0: 320x416 1 anger, 132.0ms\n",
      "0: 320x416 1 anger, 138.9ms\n",
      "0: 320x416 1 anger, 149.4ms\n",
      "0: 320x416 1 anger, 135.4ms\n",
      "0: 320x416 1 anger, 191.0ms\n",
      "0: 320x416 1 anger, 238.4ms\n",
      "0: 320x416 1 anger, 191.0ms\n",
      "0: 320x416 1 anger, 136.8ms\n",
      "0: 320x416 1 anger, 124.2ms\n",
      "0: 320x416 1 anger, 129.3ms\n",
      "0: 320x416 1 anger, 137.2ms\n",
      "0: 320x416 (no detections), 146.1ms\n",
      "0: 320x416 1 anger, 142.8ms\n",
      "0: 320x416 (no detections), 151.1ms\n",
      "0: 320x416 (no detections), 141.9ms\n",
      "0: 320x416 (no detections), 136.0ms\n",
      "0: 320x416 (no detections), 127.9ms\n",
      "0: 320x416 (no detections), 119.8ms\n",
      "0: 320x416 (no detections), 149.8ms\n",
      "0: 320x416 (no detections), 133.7ms\n",
      "0: 320x416 1 happy, 127.4ms\n",
      "0: 320x416 1 disgust, 128.2ms\n",
      "0: 320x416 (no detections), 176.9ms\n",
      "0: 320x416 1 disgust, 192.2ms\n",
      "0: 320x416 1 disgust, 149.2ms\n",
      "0: 320x416 (no detections), 125.2ms\n",
      "0: 320x416 1 disgust, 127.3ms\n",
      "0: 320x416 1 disgust, 116.2ms\n",
      "0: 320x416 1 disgust, 118.9ms\n",
      "0: 320x416 1 disgust, 128.9ms\n",
      "0: 320x416 1 disgust, 127.7ms\n",
      "0: 320x416 1 disgust, 159.8ms\n",
      "0: 320x416 (no detections), 117.7ms\n",
      "0: 320x416 (no detections), 121.7ms\n",
      "0: 320x416 (no detections), 120.6ms\n",
      "0: 320x416 (no detections), 127.3ms\n",
      "0: 320x416 (no detections), 178.2ms\n",
      "0: 320x416 (no detections), 177.6ms\n",
      "0: 320x416 (no detections), 120.8ms\n",
      "0: 320x416 1 disgust, 127.5ms\n",
      "0: 320x416 1 happy, 112.3ms\n",
      "0: 320x416 1 happy, 110.6ms\n",
      "0: 320x416 1 happy, 112.7ms\n",
      "0: 320x416 1 happy, 125.0ms\n",
      "0: 320x416 1 happy, 112.1ms\n",
      "0: 320x416 1 happy, 143.6ms\n",
      "0: 320x416 1 happy, 115.8ms\n",
      "0: 320x416 1 happy, 121.5ms\n",
      "0: 320x416 1 happy, 128.2ms\n",
      "0: 320x416 1 happy, 112.0ms\n",
      "0: 320x416 1 happy, 128.3ms\n",
      "0: 320x416 1 happy, 112.0ms\n",
      "0: 320x416 1 happy, 136.1ms\n",
      "0: 320x416 1 happy, 127.0ms\n",
      "0: 320x416 1 happy, 127.7ms\n",
      "0: 320x416 1 happy, 136.8ms\n",
      "0: 320x416 1 happy, 116.3ms\n",
      "0: 320x416 (no detections), 113.4ms\n",
      "0: 320x416 1 happy, 125.4ms\n",
      "0: 320x416 1 happy, 119.3ms\n",
      "0: 320x416 1 happy, 112.0ms\n",
      "0: 320x416 1 happy, 146.0ms\n",
      "0: 320x416 (no detections), 125.8ms\n",
      "0: 320x416 1 happy, 112.5ms\n",
      "0: 320x416 (no detections), 129.2ms\n",
      "0: 320x416 (no detections), 126.2ms\n",
      "0: 320x416 (no detections), 128.4ms\n",
      "0: 320x416 1 happy, 111.5ms\n",
      "0: 320x416 1 happy, 156.7ms\n",
      "0: 320x416 1 happy, 134.7ms\n",
      "0: 320x416 (no detections), 122.3ms\n",
      "0: 320x416 1 happy, 242.1ms\n",
      "0: 320x416 (no detections), 169.8ms\n",
      "0: 320x416 1 happy, 161.9ms\n",
      "0: 320x416 1 happy, 158.7ms\n",
      "0: 320x416 1 happy, 149.5ms\n",
      "0: 320x416 1 happy, 154.6ms\n",
      "0: 320x416 1 happy, 131.5ms\n",
      "0: 320x416 1 happy, 161.6ms\n",
      "0: 320x416 1 happy, 233.7ms\n",
      "0: 320x416 1 happy, 192.6ms\n",
      "0: 320x416 1 happy, 146.3ms\n",
      "0: 320x416 1 happy, 152.9ms\n",
      "0: 320x416 1 happy, 138.7ms\n",
      "0: 320x416 1 happy, 142.5ms\n",
      "0: 320x416 1 happy, 137.0ms\n",
      "0: 320x416 1 happy, 129.1ms\n",
      "0: 320x416 1 happy, 151.5ms\n",
      "0: 320x416 1 happy, 202.9ms\n",
      "0: 320x416 1 happy, 205.3ms\n",
      "0: 320x416 (no detections), 144.9ms\n",
      "0: 320x416 (no detections), 135.0ms\n",
      "0: 320x416 (no detections), 143.6ms\n",
      "0: 320x416 (no detections), 120.6ms\n",
      "0: 320x416 (no detections), 125.0ms\n",
      "0: 320x416 1 happy, 142.3ms\n",
      "0: 320x416 1 happy, 130.7ms\n",
      "0: 320x416 (no detections), 128.1ms\n",
      "0: 320x416 (no detections), 111.8ms\n",
      "0: 320x416 1 happy, 146.4ms\n",
      "0: 320x416 (no detections), 182.8ms\n",
      "0: 320x416 (no detections), 142.1ms\n",
      "0: 320x416 1 happy, 130.4ms\n",
      "0: 320x416 1 happy, 130.9ms\n",
      "0: 320x416 1 happy, 206.6ms\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(source=\"0\",show=True,conf=.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a8b7a9-fef4-4ba3-8f95-510f40f12d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'contempt',\n",
       " 2: 'disgust',\n",
       " 3: 'fear',\n",
       " 4: 'happy',\n",
       " 5: 'neutral',\n",
       " 6: 'sad',\n",
       " 7: 'surprise'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = model.names\n",
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8faa1b-07b5-4799-b526-66cd9631be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = model.names\n",
    "def showCamAdvanced():\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            rects = face_detect(gray, 1)\n",
    "            i=0\n",
    "            for (i, rect) in enumerate(rects):\n",
    "                # Identify face coordinates\n",
    "                (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "                face = gray[y:y+h, x:x+w]\n",
    "                # Visualize the results on the frame\n",
    "                results = model(face)\n",
    "                #results = model.predict(face,show=True,conf=.50)\n",
    "                label=None\n",
    "                # Get the annotated face\n",
    "                for r in results:\n",
    "                    for c in r.boxes.cls:\n",
    "                        label=names[int(c)]\n",
    "                        \n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Face #{}\".format(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,255), 2)\n",
    "                cv2.putText(frame,str(label) ,(x+w-10,y-10), cv2.FONT_HERSHEY_DUPLEX, 1, (255,0,0), 2)\n",
    "\n",
    "            # Display the frame with annotations\n",
    "            cv2.imshow(\"FER Detection YOLOV8\", frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "showCamAdvanced()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
